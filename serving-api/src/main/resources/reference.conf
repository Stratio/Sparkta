# API

sparta.api.host = 0.0.0.0
sparta.api.port = 9090
sparta.api.certificate-file = "/home/user/certifications/stratio.jks"
sparta.api.certificate-password = "stratio"


# ZOOKEEPER

sparta.zookeeper.connectionString = "localhost:2181"
sparta.zookeeper.storagePath = "/stratio/sparta"
sparta.zookeeper.connectionTimeout = 19000
sparta.zookeeper.sessionTimeout = 60000
sparta.zookeeper.retryAttempts = 5
sparta.zookeeper.retryInterval = 10000


# OAUTH2

oauth2.enable = "false"
# oauth2.cookieName="user"
# oauth2.url.authorize = "https://server.domain:9005/cas/oauth2.0/authorize"
# oauth2.url.accessToken = "https://server.domain:9005/cas/oauth2.0/accessToken"
# oauth2.url.profile = "https://server.domain:9005/cas/oauth2.0/profile"
# oauth2.url.logout = "https://server.domain:9005/cas/logout"
# oauth2.url.callBack = "http://callback.domain:9090/login"
# oauth2.url.onLoginGoTo = "/"
# oauth2.client.id = "userid"
# oauth2.client.secret = "usersecret"


# SPRAY

spray.can.server.ssl-encryption = "off"


# AKKA

akka.log-dead-letters = off
akka.loggers = ["akka.event.slf4j.Slf4jLogger"]
akka.logger-startup-timeout = 30s


# CONFIG

# Driver jar served by Sparta in this location
sparta.config.driverPackageLocation = "/tmp/sparta/driver"

# Plugin jar are saved in this dir
sparta.config.pluginPackageLocation = "/tmp/sparta/plugins"

# Backups files are saved in this dir
sparta.config.backupsLocation = "/tmp/sparta/backups"

# Maximun time when await to policy status change when run polices in cluster mode
sparta.config.awaitPolicyChangeStatus = 360s

# Frontend timeout
sparta.config.frontend.timeout = 20000

# Crossdata config file
#sparta.config.crossdata.reference = "/etc/sds/sparta/reference.conf"



####################################
#                                  #
#      Security configuration      #
#                                  #
####################################

# Sparta security mode implementation based on the GoSec plugin
sparta.security.manager.enabled = false

# HDFS

# The hadoop user name could be configured by two ways:
# 1. Using the enviroment variable HADOOP_USER_NAME
# 2. Using the variable hadoopUserName from properties file
# sparta.hdfs.hadoopUserName = root

# If the variable HADOOP_CONF_DIR is not defined, "hdfsMaster" variable and "hdfsPort" are used to
# connect to HDFS cluster in order to upload jars to HDFS (plugins and driver), but the Spark executors and the
# Spark driver need this environment variable defined. In producction environments is recomended use
# HADOOP_CONF_DIR because use HA in Hadoop Namenodes, and omit "hdfsMaster and hdfsPort property"
# sparta.hdfs.hdfsMaster = hadoopNameNodeAddress
# sparta.hdfs.hdfsPort = 9000

# Configuration to connect to HDFS Kerberized

# The principal name could be configured by two ways:
# 1. Using the enviroment variable SPARTA_PRINCIPAL_NAME
# 2. Using the variable principalName from properties file
# The principal name used to connect to HDFS securized have the order 1, 2
# sparta.hdfs.principalName = ""

# The keytab path could be configured by two ways:
# 1. Using the enviroment variable SPARTA_KEYTAB_PATH
# 2. Using the variable keytabPath from properties file

# sparta.hdfs.keytabPath = ""
# sparta.hdfs.reloadKeyTab = false
# sparta.hdfs.reloadKeyTabTime = 23h


### SPARK MARATHON deployments ###

sparta.marathon.docker.image = "qa.stratio.com/stratio/sparta:1.6.0"
sparta.marathon.docker.forcePullImage = false
sparta.marathon.docker.privileged = false
sparta.marathon.jar = "/opt/sds/sparta/driver/sparta-driver.jar"
sparta.marathon.template.file = "/etc/sds/sparta/marathon-app-template.json"
sparta.marathon.mesosphere.lib = "/opt/mesosphere/lib"
sparta.marathon.mesosphere.packages = "/opt/mesosphere/packages"
sparta.marathon.gracePeriodSeconds = 240
sparta.marathon.intervalSeconds = 60
sparta.marathon.timeoutSeconds = 20
sparta.marathon.maxConsecutiveFailures = 3
# sparta.marathon.sso.uri = "https://gosec2.labs.stratio.com:9005/gosec-sso"
# sparta.marathon.sso.username = "admin"
# sparta.marathon.sso.password = "1234"
# sparta.marathon.sso.clientId = "adminrouter_paas-master-1.labs.stratio.com"
# sparta.marathon.sso.redirectUri = "https://master-1.labs.stratio.com/acs/api/v1/auth/login&firstUser=false"
# sparta.marathon.tikitakka.marathon.uri = "http://master-1.labs.stratio.com:8080"
sparta.marathon.tikitakka.marathon.api.version = "v2"


# CROSSDATA configuration

crossdata.catalog.class = ${?CROSSDATA_CORE_CATALOG_CLASS}
crossdata.catalog.zookeeper.connectionString = "localhost:2181"
crossdata.catalog.zookeeper.connectionString = ${?CROSSDATA_CORE_CATALOG_ZOOKEEPER_CONNECTIONSTRING}
crossdata.catalog.zookeeper.connectionTimeout = 15s
crossdata.catalog.zookeeper.connectionTimeout = ${?CROSSDATA_CORE_CATALOG_ZOOKEEPER_CONNECTIONTIMEOUT}
crossdata.catalog.zookeeper.sessionTimeout = 60s
crossdata.catalog.zookeeper.sessionTimeout = ${?CROSSDATA_CORE_CATALOG_ZOOKEEPER_SESSIONTIMEOUT}
crossdata.catalog.zookeeper.retryAttempts = 5
crossdata.catalog.zookeeper.retryAttempts = ${?CROSSDATA_CORE_CATALOG_ZOOKEEPER_RETRYATTEMPTS}
crossdata.catalog.zookeeper.retryInterval = 10s
crossdata.catalog.zookeeper.retryInterval = ${?CROSSDATA_CORE_CATALOG_ZOOKEEPER_RETRYINTERVAL}
crossdata.catalog.zookeeper.prefix = "crossdataCluster"
crossdata.catalog.zookeeper.prefix = ${?CROSSDATA_CORE_CATALOG_PREFIX}
crossdata.storage.path = "/tmp"
crossdata.storage.path = ${?CROSSDATA_STORAGE_PATH}
crossdata.security.enable-manager = false
crossdata.security.enable-manager = ${?CROSSDATA_SECURITY_MANAGER_ENABLED}
crossdata.security.manager.class = ${?CROSSDATA_SECURITY_MANAGER_CLASS}

spark.master = "local[*]"
spark.master = ${?CROSSDATA_SERVER_CONFIG_SPARK_MASTER}
spark.ui.enabled = false
spark.ui.enabled = ${?CROSSDATA_SERVER_SPARK_UI_ENABLED}
spark.ui.port = 4045
spark.ui.port = ${?CROSSDATA_SERVER_CONFIG_SPARK_UI_PORT}
spark.executor.memory = 1G
spark.executor.memory = ${?CROSSDATA_SERVER_CONFIG_SPARK_EXECUTOR_MEMORY}
spark.executor.cores = ${?CROSSDATA_SERVER_CONFIG_SPARK_EXECUTOR_CORES}
spark.driver.memory = 1G
spark.driver.memory = ${?CROSSDATA_SERVER_CONFIG_SPARK_DRIVER_MEMORY}
spark.driver.cores = 1
spark.driver.cores = ${?CROSSDATA_SERVER_CONFIG_SPARK_DRIVER_CORES}
spark.cores.max = 1
spark.cores.max = ${?CROSSDATA_SERVER_CONFIG_SPARK_CORES_MAX}
spark.mesos.coarse = true
spark.mesos.executor.home = "/opt/spark/dist"
spark.mesos.executor.docker.image = "qa.stratio.com/stratio/stratio-spark:2.1.0.1"
spark.mesos.executor.docker.volumes = "/opt/mesosphere/packages/:/opt/mesosphere/packages/:ro,/opt/mesosphere/lib/:/opt/mesosphere/lib/:ro"
spark.hadoop.fs.hdfs.impl.disable.cache = false
spark.hadoop.fs.hdfs.impl.disable.cache = ${?CROSSDATA_HDFS_DELEGATION_TOKEN_DISABLE_CACHE}
spark.mesos.role = ${?SPARK_MESOS_ROLE}
spark.mesos.principal = ${?SPARK_MESOS_PRINCIPAL}
spark.mesos.secret = ${?SPARK_MESOS_SECRET}
spark.mesos.executor.docker.network.name = ${?CALICO_NETWORK}
spark.executorEnv.MESOS_NATIVE_JAVA_LIBRARY = "/opt/mesosphere/lib/libmesos.so"
spark.executorEnv.APP_NAME = ${?CROSSDATA_SERVER_SPARK_EXECUTOR_APP_NAME}
spark.executorEnv.CA_NAME = ${?CROSSDATA_SERVER_SPARK_EXECUTOR_CA_NAME}
spark.executorEnv.SPARK_DATASTORE_SSL_ENABLE = ${?CROSSDATA_SERVER_SPARK_DATASTORE_SSL_ENABLE}
spark.executorEnv.VAULT_HOST = ${?VAULT_HOSTS}
spark.executorEnv.VAULT_PROTOCOL = ${?VAULT_PROTOCOL}
spark.executorEnv.VAULT_PORT = ${?VAULT_PORT}
spark.locality.wait = 0