sparta {

  api {
    host = 0.0.0.0
    port = 9090
    certificate-file = "/home/user/certifications/stratio.jks"
    certificate-password = "stratio"
  }

  swagger {
    host = 0.0.0.0
    port = 9091
  }

  config {
    executionMode = mesos
    rememberPartitioner = true

    # In cluster mode and production environment is recommended set to true
    stopGracefully = true

    # All the checkpoint options is possible to set in the policy

      # Example value in cluster mode
      checkpointPath = "/user/stratio/sparta/checkpoint"

      # Example value in local mode for Stratio Platform
      # checkpointPath = "/var/sds/sparta/checkpoint"

      # Example value in local mode for debugging
      # checkpointPath = "/tmp/sparta/checkpoint"

      autoDeleteCheckpoint = true
  }

  local {
    spark.app.name = SPARTA
    spark.master = "local[*]"
    spark.driver.memory = 1G
    spark.driver.cores = 1
    spark.executor.memory = 1024m
    spark.app.name = SPARTA
    spark.sql.parquet.binaryAsString = true
    spark.streaming.concurrentJobs = 1

    # Option necessary when run benchmarks
    # spark.metrics.conf = /opt/sds/sparta/benchmark/src/main/resources/metrics.properties

    # Options to optimize the jobs
    # spark.serializer = org.apache.spark.serializer.KryoSerializer
  }

  hdfs {
    hadoopUserName = stratio
    # If the variable HADOOP_CONF_DIR is not defined, "hdfsMaster" variable and "hdfsPort" are used to connect to HDFS cluster
    hdfsMaster = hm.demo.stratio.com
    hdfsPort = 8020

    # Folders created in HDFS when run over Mesos, Yarn or StandAlone clusters
    pluginsFolder = plugins
    executionJarFolder = jarDriver
    classpathFolder = classpath
  }

  mesos {
    sparkHome = ""
    deployMode = cluster
    numExecutors = 1
    master = "mesos://mm11.demo.stratio.com:7077"

    # Spark Options for development environments

      spark.streaming.concurrentJobs = 1
      spark.mesos.coarse = true
      spark.executor.memory = 1G
      spark.driver.cores = 1
      spark.driver.memory = 1G
      spark.app.name = SPARTA
      spark.streaming.gracefulStopTimeout = 60000

      # Important options when run over Mesos Clusters
      # spark.mesos.extra.cores = 1
      # spark.executor.home=/spark-1.6.2-bin-2.6.0
      # spark.mesos.executor.docker.image=anistal/spark-final
      # spark.executor.uri=/spark-mesosphere-scala211-1.6.2-bin-hadoop2.6.0.tgz

      # Options to optimize the jobs
      # spark.serializer = org.apache.spark.serializer.KryoSerializer
  }

  yarn {
    sparkHome = ""
    master = yarn-cluster
    deployMode = cluster
    numExecutors = 1
    executorMemory = 1G
    executorCores = 1

    # Spark Options
    spark.app.name = SPARTA
  }

  standalone {
    sparkHome = ""
    master = "spark://127.0.0.1:7077"
    deployMode = cluster
    numExecutors = 1
    executorMemory = 1G
    executorCores = 1

    # Spark Options
    spark.app.name = SPARTA
  }

  zookeeper {
    connectionString = "zk.demo.stratio.com"
    connectionTimeout = 15000
    sessionTimeout = 60000
    retryAttempts = 5
    retryInterval = 10000
  }

  akka {
    controllerActorInstances = 5
  }
}

oauth2 {
  enable = "false"

  url {
    authorize = "https://server.domain:9005/cas/oauth2.0/authorize"
    accessToken = "https://server.domain:9005/cas/oauth2.0/accessToken"
    profile = "https://server.domain:9005/cas/oauth2.0/profile"
    logout = "https://server.domain:9005/cas/logout"
    callBack = "http://callback.domain:9090/login"
    onLoginGoTo = "/"
  }
  client{
    id = "userid"
    secret = "usersecret"
  }
  cookieName="user"
}

spray.can {
  server {
    ssl-encryption = "off"
  }
}