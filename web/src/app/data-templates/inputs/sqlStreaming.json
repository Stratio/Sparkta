  {
    "name": "StreamingSQL",
    "icon": "SQL",
    "className": "SQLInputStepStreaming",
    "classPrettyName": "StreamingSQL",
    "crossdataCatalog": true,
    "arity": ["NullaryToNary"],
    "supportedEngines": ["Streaming"],
    "supportedDataRelations": ["ValidData"],
    "description": "Allows you to execute any SQL to monitor tables migrating data in streaming processes with finite or infinite duration",
    "properties": [
      {
        "propertyId": "query",
        "propertyName": "_QUERY_",
        "propertyType": "textarea",
        "contentType": "SQL",
        "width": 12,
        "required": true,
        "tooltip": "Query to retrieve data from any table available in Crossdata or any temporal table. The result will be stored in another temporal table named after the input step.",
        "placeholder": "select * from tableName",
        "qa": "fragment-details-sql-query"
      },
      {
        "propertyId": "continuousSentences",
        "propertyName": "_CONTINUOUS_SENTENCES_",
        "propertyType": "list",
        "required": false,
        "complexForm": true,
        "tooltip": "SQL sentences executed on each window. Useful to refresh input tables.",
        "qa": "fragment-details-continuousSentences",
        "fields": [
          {
            "propertyId": "query",
            "propertyName": "_SQL_QUERY_",
            "propertyType": "textarea",
            "required": false,
            "contentType": "SQL",
            "width": 12,
            "tooltip": "SQL query to execute.",
            "qa": "fragment-details-sql-continuousSentences-query"
          }
        ]
      },
      {
        "propertyId": "limitRecords",
        "propertyName": "_LIMIT_RECORDS_",
        "propertyType": "text",
         "tooltip": "Limit the records processed on each streaming window.",
         "qa": "fragment-details-sql-limitRecords"
      },
      {
         "propertyId": "offsetFields",
         "propertyName": "_OFFSET_FIELDS_",
         "propertyType": "list",
         "required": false,
         "tooltip": "List of fields used as offsets in the source table.",
         "qa": "fragment-details-datetime-fields",
         "fields": [
            {
               "propertyId": "offsetField",
               "propertyName": "_OFFSET_FILED_",
               "propertyType": "text",
               "required": true,
               "width": 4,
               "tooltip": "Offset field in the source table",
               "qa": "fragment-details-sql-offsetField"
            },
            {
               "propertyId": "offsetValue",
               "propertyName": "_OFFSET_VALUE_",
               "propertyType": "text",
               "width": 4,
               "tooltip": "Initial offset value",
               "qa": "fragment-details-sql-offsetValue"
            },
            {
               "propertyId": "offsetOperator",
               "propertyName": "_OFFSET_OPERATOR_",
               "propertyType": "select",
               "required": true,
               "width": 3,
               "values": [
                  {
                     "label": ">",
                     "value": ">"
                  },
                  {
                     "label": ">=",
                     "value": ">="
                  },
                  {
                     "label": "<",
                     "value": "<"
                  },
                  {
                     "label": "<=",
                     "value": "<="
                  }
               ],
               "default": ">=",
               "tooltip": "Offset operator to generate incremental or decremental queries in the source table",
               "qa": "fragment-details-sql-offsetOperator"
            }
         ]
      },
      {
        "propertyId": "storeOffsetAfterWritingOutputs",
        "propertyName": "_STORE_OFFSET_AFTER_WRITING_OUTPUTS_",
        "propertyType": "boolean",
        "tooltip": "Store offsets in Kafka after all workflow outputs writes correctly. Is possible to simulates ONE TRANSACTION policy. It's mandatory to disable the auto commit when checked.",
        "default": true,
        "qa": "fragment-details-sql-offset-after-write"
      },
      {
        "propertyId": "offsetLocation",
        "propertyName": "_OFFSET_LOCATION_",
        "propertyType": "select",
        "values": [
          {
            "label": "Memory",
            "value": "MEMORY"
          },
          {
            "label": "Zookeeper",
            "value": "ZOOKEEPER"
          }
        ],
        "default": "MEMORY",
        "required": false,
        "tooltip": "Location where the offsets are saved",
        "qa": "fragment-details-sql-offsetLocation"
      },
       {
          "propertyId": "resetOffsetOnStart",
          "propertyName": "_RESET_ON_START_",
          "propertyType": "boolean",
          "default": false,
          "visible": [
             [
                {
                   "propertyId": "offsetLocation",
                   "value": "ZOOKEEPER"
                }
             ]
          ],
          "tooltip": "If checked, the application will reset any stored offsets when starting the streaming process.",
          "qa": "fragment-details-sql-resetOffsetOnStart"
       },
       {
          "propertyId": "ignoreStartedStatus",
          "propertyName": "_IGNORE_STARTED_STATUS_",
          "propertyType": "boolean",
          "default": false,
          "visible": [
             [
                {
                   "propertyId": "offsetLocation",
                   "value": "ZOOKEEPER"
                },
                {
                   "propertyId": "resetOffsetOnStart",
                   "value": true
                }
             ]
          ],
          "tooltip": "Force the offsets reset ignoring the workflow status. If not checked, the offsets will be restarted only when the workflow status is set to 'Not started'.",
          "qa": "fragment-details-sql-ignoreStartedStatus"
       },
      {
        "propertyId": "stopContexts",
        "propertyName": "_STOP_CONTEXTS_WHEN_EMPTY_",
        "propertyType": "boolean",
        "default": false,
         "float": "true",
         "width": 4,
        "tooltip": "Allows the application to stop the Spark contexts after waiting for the processing of all received data to be completed",
        "qa": "fragment-details-sql-stopContextsWhenEmpty"
      },
       {
          "propertyId": "finishAppWhenEmpty",
          "propertyName": "_FINISH_APP_WHEN_EMPTY_",
          "propertyType": "boolean",
          "default": false,
          "width": 4,
          "tooltip": "If checked the application will shut down itself when no more data if left to be processed. It simulates a finite batch.",
          "qa": "fragment-details-sql-stopWhenEmpty"
       }
    ]
  }
