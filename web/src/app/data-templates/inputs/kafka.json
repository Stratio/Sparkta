  {
    "name": "Kafka",
    "classPrettyName": "Kafka",
    "className": "KafkaInputStep",
    "icon": "Kafka",
     "arity": ["NullaryToNary"],
     "supportedEngines": ["Streaming"],
     "supportedDataRelations": ["ValidData"],
    "description": "Apache Kafka is publish-subscribe messaging system rethought as a distributed commit log.",
    "properties": [
      {
        "propertyId": "bootstrap.servers",
        "propertyName": "_BOOTSTRAP_SERVERS_",
        "propertyType": "list",
        "default": "",
        "required": true,
        "tooltip": "List of host/port pairs to use for establishing the initial connection to the Kafka cluster",
        "qa": "fragment-details-stratio-kafkadirect-bootstrap-servers",
        "fields": [
          {
            "propertyId": "host",
            "propertyName": "_HOST_",
            "propertyType": "text",
            "default": "{{{Environment.KAFKA_BROKER_HOST}}}",
            "required": true,
            "width": 6,
            "tooltip": "Server address. Default value set to localhost",
            "hidden": false,
            "qa": "fragment-details-stratio-kafkadirect-broker"
          },
          {
            "propertyId": "port",
            "propertyName": "_PORT_",
            "propertyType": "text",
            "default": "{{{Environment.KAFKA_BROKER_PORT}}}",
            "required": true,
            "width": 5,
            "tooltip": "Server port. Default value set to 9092",
            "hidden": false,
            "qa": "fragment-details-stratio-kafkadirect-port"
          }
        ]
      },
       {
          "propertyId": "consumerStrategy",
          "propertyName": "_KAFKA_CONSUMER_STRATEGY_",
          "propertyType": "select",
          "values": [
             {
                "label": "Subscribe",
                "value": "SUBSCRIBE"
             },
             {
                "label": "Assign",
                "value": "ASSIGN"
             }
          ],
          "default": "SUBSCRIBE",
          "required": true,
          "tooltip": "Consumer strategy.",
          "qa": "fragment-details-kafka-consumer-strategy"
       },
      {
        "propertyId": "topics",
        "propertyName": "_TOPICS_",
        "propertyType": "list",
        "required": false,
         "visible": [
            [
               {
                  "propertyId": "consumerStrategy",
                  "value": "SUBSCRIBE"
               }
            ]
         ],
        "tooltip": "List of Kafka topic names. Where messages will be published. At least one is required.",
        "qa": "fragment-details-stratio-kafkadirect-topics",
        "fields": [
          {
            "propertyId": "topic",
            "propertyName": "_TOPIC_",
            "propertyType": "text",
             "width": 8,
            "required": false,
            "tooltip": "Topic to connect.",
            "placeholder": "topicName",
            "hidden": false,
            "qa": "fragment-details-stratio-kafkadirect-topic"
          }
        ]
      },
       {
          "propertyId": "topicPartitions",
          "propertyName": "_TOPIC_PARTITIONS_",
          "propertyType": "list",
          "required": false,
          "visible": [
             [
                {
                   "propertyId": "consumerStrategy",
                   "value": "ASSIGN"
                }
             ]
          ],
          "tooltip": "List of Kafka topic and partitions. Where messages will be published. At least one is required.",
          "qa": "fragment-details-stratio-kafkadirect-topic-partitions",
          "fields": [
             {
                "propertyId": "topic",
                "propertyName": "_TOPIC_",
                "propertyType": "text",
                "width": 4,
                "required": false,
                "tooltip": "Topic to connect.",
                "placeholder": "topicName",
                "hidden": false,
                "qa": "fragment-details-stratio-kafkadirect-topic"
             },
             {
                "propertyId": "partition",
                "propertyName": "_KAFKA_PARTITION_",
                "propertyType": "text",
                "width": 4,
                "required": false,
                "tooltip": "Partition to connect.",
                "placeholder": "partition",
                "hidden": false,
                "qa": "fragment-details-stratio-kafkadirect-partition"
             }
          ]
       },
      {
          "propertyId": "group.id",
          "propertyName": "_GROUP_ID_",
          "propertyType": "text",
          "required": false,
          "tooltip": "Identifies the consumer group this consumer belongs to.",
          "qa": "fragment-details-stratio-kafkadirect-group-id"
       },
      {
          "propertyId": "value.deserializer.inputFormat",
          "propertyName": "_DESERIALIZER_INPUT_FORMAT_",
          "propertyType": "select",
          "values": [
             {
                "label": "String",
                "value": "STRING"
             },
             {
                "label": "Json",
                "value": "JSON"
             },
             {
                "label": "Avro",
                "value": "AVRO"
             },
             {
               "label": "Binary",
               "value": "BINARY"
             },
             {
               "label": "SchemaRegistry",
               "value": "SCHEMAREGISTRY"
             }
          ],
          "default": "STRING",
          "required": true,
          "tooltip": "Deserializer format given to all the incoming messages.",
          "qa": "fragment-details-kafka-deserializer-input-format"
       },
      {
          "propertyId": "outputField",
          "propertyName": "_OUTPUT_FIELD_",
          "propertyType": "text",
          "default": "{{{Global.DEFAULT_OUTPUT_FIELD}}}",
          "required": false,
          "visible": [
             [
                {
                   "propertyId": "value.deserializer.inputFormat",
                   "value": "STRING"
                }
             ]
          ],
          "tooltip": "Name assigned to the output field generated",
          "qa": "fragment-details-kafka-outputField"
       },
      {
          "propertyId": "value.deserializer.json.schema.fromRow",
          "propertyName": "_SCHEMA_FROM_ROW_",
          "propertyType": "boolean",
          "required": true,
          "visible": [
             [
                {
                   "propertyId": "value.deserializer.inputFormat",
                   "value": "JSON"
                }
             ]
          ],
          "default": true,
          "tooltip": "If checked, each row schema will be inferred from its content. Feature only available choosing JSON as deserializer format.",
          "qa": "workflow-transformation-kafka-schema-fromRow"
       },
      {
          "propertyId": "value.deserializer.json.schema.inputMode",
          "propertyName": "_INPUT_SCHEMA_FROM_",
          "propertyType": "select",
          "visible": [
             [
                {
                   "propertyId": "value.deserializer.inputFormat",
                   "value": "JSON"
                },
                {
                   "propertyId": "value.deserializer.json.schema.fromRow",
                   "value": false
                }
             ]
          ],
          "values": [
             {
                "label": "Spark format",
                "value": "SPARKFORMAT"
             },
             {
                "label": "Example",
                "value": "EXAMPLE"
             }
          ],
          "default": "SPARKFORMAT",
          "required": true,
          "tooltip": "Option that allows you to paste a valid schema or an event example where to retrieve the schema from. If Spark format is chosen then the user is able to pick between pasting a JSON schem or a Spark schema. Only available with JSON as deserializer format.",
          "qa": "workflow-transformation-kafka-schema-mode"
       },
      {
          "propertyId": "value.deserializer.json.schema.provided",
          "propertyName": "_DESERIALIZER_JSON_SCHEMA_",
          "propertyType": "textarea",
          "contentType": "JSON",
          "width": 12,
          "tooltip": "Schema in json/Spark format or from example",
          "default": "",
          "visible": [
             [
                {
                   "propertyId": "value.deserializer.inputFormat",
                   "value": "JSON"
                },
                {
                   "propertyId": "value.deserializer.json.schema.fromRow",
                   "value": false
                }
             ]
          ],
          "required": false,
          "qa": "fragment-details-kafka-deserializer-json"
       },
       {
          "propertyId": "value.deserializer.avro.schema",
          "propertyName": "_DESERIALIZER_AVRO_SCHEMA_",
          "propertyType": "textarea",
          "contentType": "JSON",
          "width": 12,
          "tooltip": "Parses an Apache Avro schema.",
          "default": "",
          "visible": [
             [
                {
                   "propertyId": "value.deserializer.inputFormat",
                   "value": "AVRO"
                }
             ]
          ],
          "required": false,
          "qa": "fragment-details-kafka-deserializer-avro-schema"
       },
      {
        "propertyId": "value.deserializer.schema.registry.url",
        "propertyName": "_DESERIALIZER_SCHEMAREGISTRY_SCHEMA_URL_",
        "propertyType": "text",
        "contentType": "URL",
        "width": 12,
        "tooltip": "Get the Schema Registry schema. E.g 'https://schemaNameinEos.marathon.mesos:8089'",
        "default": "",
        "visible": [
          [
            {
              "propertyId": "value.deserializer.inputFormat",
              "value": "SCHEMAREGISTRY"
            }
          ]
        ],
        "required": true,
        "qa": "fragment-details-kafka-deserializer-schemaRegistry-schema"
      },
      {
        "propertyId": "tlsSchemaRegistryEnabled",
        "propertyName": "_TLS_SCHEMA_REGISTRY_ENABLE_",
        "propertyType": "boolean",
        "tooltip": "Enable TLS connection to connect to Kafka schema registry",
        "default": false,
        "visible": [
          [
            {
              "propertyId": "value.deserializer.inputFormat",
              "value": "SCHEMAREGISTRY"
            }
          ]
        ],
        "qa": "fragment-details-kafka-tls-registry"
      },
      {
        "propertyId": "partition.assignment.strategy",
        "propertyName": "_PARTITION_STRATEGY_",
        "propertyType": "select",
        "values": [
          {
            "label": "Range",
            "value": "range"
          },
          {
            "label": "Round Robin",
            "value": "roundrobin"
          }
        ],
        "default": "range",
        "tooltip": "The class name of the partition assignment strategy that the client will use to distribute partition ownership amongst consumer instances when group management is used.",
        "required": true,
        "qa": "fragment-details-stratiokafkadirect-partition-assignment-strategy"
      },
      {
        "propertyId": "locationStrategy",
        "propertyName": "_LOCATION_STRATEGY_",
        "propertyType": "select",
        "values": [
          {
            "label": "Prefer Consistent",
            "value": "preferconsistent"
          },
          {
            "label": "Prefer Brokers",
            "value": "preferbrokers"
          }
        ],
        "default": "preferconsistent",
        "tooltip": "Prefer Consistent will distribute partitions evenly across available executors. If your executors are on the same hosts as your Kafka brokers, use PreferBrokers",
        "required": true,
        "qa": "fragment-details-stratiokafkadirect-locationStrategy"
      },
      {
        "propertyId": "auto.offset.reset",
        "propertyName": "_KAFKA_AUTO_OFFSET_",
        "propertyType": "select",
        "values": [
           {
              "label": "Latest",
              "value": "latest"
           },
           {
            "label": "Earliest",
            "value": "earliest"
           }
        ],
        "default": "latest",
        "required": true,
        "tooltip": "Earliest : automatically reset the offset to the earliest offset. Latest: automatically reset the offset to the latest offset",
        "qa": "fragment-details-stratiokafkadirect-auto-offset"
      },
       {
          "propertyId": "spark.streaming.kafka.consumer.poll.ms",
          "propertyName": "_MAX_POLL_TIMEOUT_",
          "propertyType": "text",
          "default": "{{{Environment.KAFKA_MAX_POLL_TIMEOUT}}}",
          "required": false,
          "tooltip": "If the timeout is too low and the Kafka brokers need more time to answer there the user will encounter many “TASK FAILED”s messages, which causes a delay in the preparation of the assigned tasks into the executors. However, if this timeout is too high the Spark executor wastes a lot of time doing nothing and produces large delays (pollTimeout + task scheduling in the new executor).",
          "qa": "fragment-details-kafka-maxPollTimeout"
       },
       {
          "propertyId": "max.partition.fetch.bytes",
          "propertyName": "_KAFKA_MAX_PARTITION_FETCH_BYTES_",
          "propertyType": "text",
          "required": false,
          "tooltip": "The maximum amount of data per-partition the server will return.",
          "default": "{{{Environment.KAFKA_MAX_PARTITION_FETCH_BYTES}}}",
          "qa": "fragment-details-kafka-max-partition-fetch-bytes"
       },
       {
          "propertyId": "session.timeout.ms",
          "propertyName": "_KAFKA_SESSION_TIMEOUT_",
          "propertyType": "text",
          "required": false,
          "tooltip": "The timeout used to detect failures when using Kafka's group management facilities. When a consumer's heartbeat is not received within the session timeout, the broker will mark the consumer as failed and rebalance the group.",
          "default": "{{{Environment.KAFKA_SESSION_TIMEOUT}}}",
          "qa": "fragment-details-kafka-session-timeout"
       },
       {
          "propertyId": "request.timeout.ms",
          "propertyName": "_KAFKA_REQUEST_TIMEOUT_",
          "propertyType": "text",
          "required": false,
          "tooltip": "The configuration controls the maximum amount of time the client will wait for the response of a request. If the response is not received before the timeout elapses the client will resend the request if necessary or fail the request if retries are exhausted.",
          "default": "{{{Environment.KAFKA_REQUEST_TIMEOUT}}}",
          "qa": "fragment-details-kafka-request-timeout"
       },
       {
          "propertyId": "heartbeat.interval.ms",
          "propertyName": "_KAFKA_HEARTBEAT_INTERVAL_",
          "propertyType": "text",
          "required": false,
          "tooltip": "The expected time between heartbeats to the consumer coordinator when using Kafka's group management facilities. Heartbeats are used to ensure that the consumer's session stays active and to facilitate rebalancing when new consumers join or leave the group. The value must be set lower than <code>session.timeout.ms</code>, but typically should be set no higher than 1/3 of that value. It can be adjusted even lower to control the expected time for normal rebalances.",
          "default": "{{{Environment.KAFKA_HEARTBEAT_INTERVAL}}}",
          "qa": "fragment-details-kafka-heartbeat-interval"
       },
       {
          "propertyId": "fetch.max.wait.ms",
          "propertyName": "_KAFKA_FETCH_MAX_WAIT_",
          "propertyType": "text",
          "required": false,
          "tooltip": "The maximum amount of time the server will block before answering the fetch request if there isn't sufficient data to immediately satisfy the requirement given by fetch.min.bytes.",
          "default": "{{{Environment.KAFKA_FETCH_MAX_WAIT}}}",
          "qa": "fragment-details-kafka-fetch-max-wait"
       },
       {
          "propertyId": "spark.streaming.kafka.maxRatePerPartition",
          "propertyName": "_MAX_RATE_PER_PARTITION_",
          "propertyType": "text",
          "default": "{{{Environment.KAFKA_MAX_RATE_PER_PARTITION}}}",
          "required": false,
          "tooltip": "Limit the rate per partition when backpressure is enabled.",
          "qa": "fragment-details-kafka-maxRatePerPartition"
       },
       {
          "propertyId": "retry.backoff.ms",
          "propertyName": "_KAFKA_RETRY_BACKOFF_",
          "propertyType": "text",
          "default": "{{{Environment.KAFKA_RETRY_BACKOFF}}}",
          "required": false,
          "tooltip": "The amount of time to wait before attempting to retry a failed request to a given topic partition. This avoids repeatedly sending requests in a tight loop under some failure scenarios.",
          "qa": "fragment-details-kafka-maxRatePerPartition"
       },
       {
          "propertyId": "spark.streaming.kafka.consumer.cache.enabled",
          "propertyName": "_CACHED_CONSUMER_",
          "propertyType": "boolean",
          "default": false,
          "required": true,
          "tooltip": "Disable the caching for Kafka consumers. Disabling the cache may be needed to workaround the problem described in SPARK-19185.",
          "qa": "fragment-details-kafka-cacheConsumer"
       },
      {
        "propertyId": "enable.auto.commit",
        "propertyName": "_KAFKA_ENABLE_AUTOCOMMIT_",
        "propertyType": "boolean",
        "tooltip": "If true the consumer's offset will be periodically committed in the background.",
        "default": false,
        "qa": "fragment-details-kafka-enable-autocommit"
      },
      {
        "propertyId": "auto.commit.interval.ms",
        "propertyName": "_KAFKA_AUTO_COMMIT_INTERVAL_",
        "propertyType": "text",
        "tooltip": "The frequency in milliseconds that the consumer offsets are auto-committed to Kafka.",
        "default": "{{{Environment.KAFKA_AUTO_COMMIT_INTERVAL}}}",
        "visible": [
          [
            {
              "propertyId": "enable.auto.commit",
              "value": true
            }
          ]
        ],
        "qa": "fragment-details-kafka-commit-interval"
      },
       {
          "propertyId": "storeOffsetInKafka",
          "propertyName": "_KAFKA_STORE_OFFSET_ITSELF_",
          "propertyType": "boolean",
          "tooltip": "Store offsets in Kafka after all workflow outputs writes correctly. Is possible to simulates ONE TRANSACTION policy. It's mandatory to disable the auto commit when checked.",
          "default": true,
          "visible": [
             [
                {
                   "propertyId": "enable.auto.commit",
                   "value": false
                }
             ]
          ],
          "qa": "fragment-details-kafka-offset-in-kafka"
       },
       {
          "propertyId": "commitOffsetsNumRetries",
          "propertyName": "_KAFKA_COMMIT_OFFSET_NUM_RETRIES_",
          "propertyType": "text",
          "tooltip": "Number of attempts to commit offsets.",
          "default": "50",
          "visible": [
             [
                {
                   "propertyId": "storeOffsetInKafka",
                   "value": true
                }
             ]
          ],
          "qa": "fragment-details-kafka-commit-offsets-retries"
       },
       {
          "propertyId": "commitOffsetsWait",
          "propertyName": "_KAFKA_COMMIT_OFFSET_WAIT_",
          "propertyType": "text",
          "tooltip": "Time in milliseconds to wait after each commit offset attempt.",
          "default": "100",
          "visible": [
             [
                {
                   "propertyId": "storeOffsetInKafka",
                   "value": true
                }
             ]
          ],
          "qa": "fragment-details-kafka-commit-offsets-retries"
       },
      {
        "propertyId": "tlsEnabled",
        "propertyName": "_TLS_ENABLE_",
        "propertyType": "boolean",
        "tooltip": "Enable TLS connection to connect to Kafka brokers getting certs from vault in Spark job",
        "default": false,
        "qa": "fragment-details-kafka-tls"
      },
      {
        "propertyId": "inputOptions",
        "propertyName": "_KAFKA_PROPERTIES_",
        "propertyType": "list",
        "required": false,
        "tooltip": "Values set here will override the ones in the default configuration.",
        "qa": "fragment-details-kafka-properties",
        "fields": [
          {
            "propertyId": "inputOptionsKey",
            "propertyName": "_KAFKA_PROPERTY_KEY_",
            "propertyType": "text",
             "width": 4,
            "required": false,
            "qa": "fragment-details-kafka-kafkaPropertyKey"
          },
          {
            "propertyId": "inputOptionsValue",
            "propertyName": "_KAFKA_PROPERTY_VALUE_",
            "propertyType": "text",
             "width": 4,
            "required": false,
            "qa": "fragment-details-kafka-kafkaPropertyValue"
          }
        ]
      }
    ]
  }
