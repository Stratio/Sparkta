  {
    "name": "Avro",
    "icon": "Avro",
    "className": "AvroOutputStep",
    "classPrettyName": "Avro",
    "arity": ["NullaryToNullary", "NaryToNullary"],
    "supportedEngines": ["Streaming", "Batch"],
    "description": "Serializes data in a compact binary format. It can provide both a serialization format for persistent data, and a wire format for communication between Hadoop nodes.",
    "properties": [
      {
        "propertyId": "path",
        "propertyName": "_PATH_",
        "propertyType": "text",
        "required": true,
        "tooltip": "Path used to persist the transformed data. Please note that, in order to write to the HDFS specified in the tenant configuration, also relative paths can be used (e.g. /user/sparta-server/) without the namenode details (e.g. hdfs:///addressNamenode:8020/user/sparta-server/)",
        "qa": "fragment-details-avro-path"
      },
       {
          "propertyId": "errorSink",
          "propertyName": "_ERROR_SINK_",
          "propertyType": "boolean",
          "tooltip": "If checked, this output can be used to send error events. This feature can be configured through the errors management settings.",
          "default": false,
          "qa": "fragment-details-errorSink"
       },
      {
        "propertyId": "saveOptions",
        "propertyName": "_AVRO_SAVE_PROPERTIES_",
        "propertyType": "list",
        "required": false,
        "qa": "fragment-details-avro-save-properties",
        "fields": [
          {
            "propertyId": "saveOptionsKey",
            "propertyName": "_SAVE_OPTIONS_KEY_",
            "propertyType": "text",
            "width": 4,
            "required": false,
            "qa": "fragment-details-avro-saveOptionsKey"
          },
          {
            "propertyId": "saveOptionsValue",
            "propertyName": "_SAVE_OPTIONS_VALUE_",
            "propertyType": "text",
             "width": 4,
            "required": false,
            "qa": "fragment-details-avro-saveOptionsValue"
          }
        ]
      }
    ],
    "writer": [
      {
        "propertyId": "saveMode",
        "propertyName": "_SAVEMODE_",
        "propertyType": "select",
        "required": true,
        "default": "Append",
        "tooltip": "Specifies a Save mode. According to the desired output step (e.g. Postgres), it is possible to select not only the native Spark save modes but also an Upsert save mode that requires the setting of the primary key fields property.",
        "qa": "save-mode-writer",
        "values": [
          {
            "label": "Append",
            "value": "Append"
          },
          {
            "label": "Error if exists",
            "value": "ErrorIfExists"
          },
          {
            "label": "Ignore",
            "value": "Ignore"
          },
          {
            "label": "Overwrite",
            "value": "Overwrite"
          }
        ]
      },
      {
        "propertyId": "partitionBy",
        "propertyName": "_PARTITION_BY_",
        "propertyType": "text",
        "required": false,
        "tooltip": "Partition the output by one or more fields, separated by ','. This property is supported by outputs that write on file systems",
        "qa": "partition-by-writer"
      }

    ]
  }
