/*
 * Copyright (C) 2015 Stratio (http://stratio.com)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *         http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.stratio.sparta.plugin.parser.datetime

import java.io.{Serializable => JSerializable}
import java.text.SimpleDateFormat
import java.util.{Date, TimeZone}

import com.stratio.sparta.sdk.{Parser, TypeOp}
import org.apache.spark.sql.Row
import org.apache.spark.sql.types.StructType
import org.joda.time.format.{DateTimeFormatter, ISODateTimeFormat}
import com.stratio.sparta.sdk.AggregationTime._
import com.github.nscala_time.time.Imports._
import com.stratio.sparta.sdk.ValidatingPropertyMap._

class DateTimeParser(order: Integer,
                     inputField: String,
                     outputFields: Seq[String],
                     schema: StructType,
                     properties: Map[String, JSerializable])
  extends Parser(order, inputField, outputFields, schema, properties) {

  val formats = properties.getString("inputFormat", None)
  val granularityProperty = properties.getString(GranularityPropertyName, None)

  //scalastyle:off
  override def parse(row: Row, removeRaw: Boolean): Row = {
    val inputValue = row.get(inputFieldIndex)
    val newData = {
      val formatterOption = DateTimeParser.formatter(formats)
      outputFields.map(outputField => {
        val outputSchemaValid = outputFieldsSchema.find(field => field.name == outputField)
        outputSchemaValid match {
          case Some(outSchema) =>
            if (formatterOption.isDefined && !inputValue.isInstanceOf[Date]) {
              val parsedDate = formatterOption.get match {
                case Right("unix") =>
                  new DateTime(inputValue.toString.toLong * 1000L)
                case Right("unixMillis") =>
                  new DateTime(inputValue.toString.toLong)
                case Right("autoGenerated") =>
                  new DateTime()
                case Right("hive") =>
                  new DateTime(getDateFromHiveFormat(inputValue.toString))
                case Left(formatter) =>
                  formatter.parseDateTime(inputValue.toString)
              }

              TypeOp.transformValueByTypeOp(outSchema.dataType,
                granularityProperty.fold(parsedDate.getMillis) { granularity => truncateDate(parsedDate, granularity) }
                  .asInstanceOf[Any])
            } else TypeOp.transformValueByTypeOp(outSchema.dataType, inputValue)
          case None =>
            throw new IllegalStateException(s"Impossible to parse outputField: $outputField in the schema")
        }
      })
    }
    val prevData = if (removeRaw) row.toSeq.drop(1) else row.toSeq

    Row.fromSeq(prevData ++ newData)
  }

  protected def getDateFromHiveFormat(hiveFormatDate: String): Date = {
    val sdf = new SimpleDateFormat("yyyy-MM-dd HH:mm:ss")
    sdf.setTimeZone(TimeZone.getTimeZone("UTC"))
    sdf.parse(hiveFormatDate)
  }
}

object DateTimeParser {

  val formatMethods = classOf[ISODateTimeFormat].getMethods.toSeq.map(x => (x.getName, x)).toMap

  def formatter(formats: Option[String]): Option[Either[DateTimeFormatter, String]] = {
    formats match {
      case Some(format) =>
        format match {
          case "unix" => Some(Right("unix"))
          case "unixMillis" => Some(Right("unixMillis"))
          case "autoGenerated" => Some(Right("autoGenerated"))
          case "hive" => Some(Right("hive"))
          case _ => Some(Left(formatMethods(format).invoke(None).asInstanceOf[DateTimeFormatter]))
        }
      case None => None
    }
  }
}
