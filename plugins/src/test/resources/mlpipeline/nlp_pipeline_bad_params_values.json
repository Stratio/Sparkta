[
    {
        "name": "Tokenizer",
        "className": "org.apache.spark.ml.feature.Tokenizer",
        "uid": "t1",
        "properties": {
            "inputCol": "text",
            "outputCol": "words"
        }
    },
    {
        "name": "HashingTF",
        "className": "org.apache.spark.ml.feature.HashingTF",
        "uid": "h1",
        "properties": {
            "inputCol": "words",
            "numFeatures": "aaaaaaa",
            "outputCol": "features"

        }
    },
    {
        "name": "LogisticRegression",
        "uid": "l1",
        "className": "org.apache.spark.ml.classification.LogisticRegression",
        "properties": {
            "maxIter": "bbbbb",
            "regParam": "*************",
            "fitIntercept": false
        }
    }
]