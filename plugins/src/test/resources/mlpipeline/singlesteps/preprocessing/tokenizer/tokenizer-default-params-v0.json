{
  "nodes": [
    {
      "configuration": {
        "inputCol": "sentence",
        "outputCol": ""
      },
      "supportedEngines": [
        "Batch"
      ],
      "classPrettyName": "Tokenizer",
      "className": "org.apache.spark.ml.feature.Tokenizer",
      "arity": [
        "NullaryToNullary",
        "NullaryToUnary",
        "UnaryToNullary",
        "UnaryToUnary"
      ],
      "stepType": "Preprocessing",
      "writer": {
        "tableName": null,
        "errorTableName": null,
        "saveMode": "Append",
        "constraintType": "primaryKey",
        "primaryKey": null,
        "uniqueConstraintName": null,
        "uniqueConstraintFields": null,
        "partitionBy": null
      },
      "name": "Tokenizer",
      "hasErrors": false,
      "errors": [
        {
          "propertyName": "inputCol",
          "type": "required"
        },
        {
          "propertyName": "outputCol",
          "type": "required"
        }
      ],
      "createdNew": false,
      "created": true,
      "uiConfiguration": {
        "position": {
          "x": 339.06002515948427,
          "y": 191.52431585156785
        }
      },
      "description": ""
    }
  ],
  "edges": [],
  "svgPosition": {
    "k": 1.086489325159504,
    "x": 195.61490207590748,
    "y": -43.08912468120565
  }
}
